{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af8a2c0-45fe-4d13-bebd-0dca87a7b71f",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c611c8-2226-433c-bf5f-343cc0b094af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리를 임포트합니다.\n",
    "import os\n",
    "from typing import Tuple, Callable, Union, List\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import timm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms import AutoAugment, AutoAugmentPolicy\n",
    "import albumentations as A\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f69e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 시드 설정 함수\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 시드 값 설정\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d69e6a-a719-4a97-92ca-6354c873313f",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f97229-e29f-479d-abab-0db8219d1803",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        root_dir: str, \n",
    "        info_df: pd.DataFrame, \n",
    "        transform: Callable = None,  # transform을 선택적으로 설정\n",
    "        is_inference: bool = False\n",
    "    ):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_inference = is_inference\n",
    "        self.image_paths = info_df['image_path'].tolist()\n",
    "        \n",
    "        if not self.is_inference:\n",
    "            self.targets = info_df['target'].tolist()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Union[Tuple[torch.Tensor, int], Image.Image]:\n",
    "        img_path = os.path.join(self.root_dir, self.image_paths[index])\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        if self.is_inference:\n",
    "            return image  # TTA를 위해 원본 이미지 반환\n",
    "        else:\n",
    "            image = self.transform(image)\n",
    "            target = self.targets[index]\n",
    "            return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c07d2d0-9585-45ce-8ece-4f69b98f6dd4",
   "metadata": {},
   "source": [
    "# Transform Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b1855c1-cf13-476d-aabd-d78e9e082ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchvisionTransform:\n",
    "    def __init__(self, is_train: bool = True):\n",
    "        common_transforms = [\n",
    "            transforms.Resize((448, 448)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "        \n",
    "        if is_train:\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    AutoAugment(policy=AutoAugmentPolicy.IMAGENET),  # 훈련 시 AutoAugment 적용\n",
    "                ] + common_transforms\n",
    "            )\n",
    "        else:\n",
    "            self.transform = transforms.Compose(common_transforms)\n",
    "\n",
    "    def __call__(self, image: Image.Image) -> torch.Tensor:\n",
    "        return self.transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a683988-0f73-4e43-907b-0d5209550abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlbumentationsTransform:\n",
    "    def __init__(self, is_train: bool = True):\n",
    "        # 공통 변환 설정: 이미지 리사이즈, 정규화, 텐서 변환\n",
    "        common_transforms = [\n",
    "            A.Resize(448, 448),  # 이미지를 448x448 크기로 리사이즈\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 정규화\n",
    "            ToTensorV2()  # albumentations에서 제공하는 PyTorch 텐서 변환\n",
    "        ]\n",
    "        \n",
    "        if is_train:\n",
    "            # 훈련용 변환: 랜덤 수평 뒤집기, 랜덤 회전, 랜덤 밝기 및 대비 조정 추가\n",
    "            self.transform = A.Compose(\n",
    "                [\n",
    "                    A.HorizontalFlip(p=0.5),  # 50% 확률로 이미지를 수평 뒤집기\n",
    "                    A.Rotate(limit=15),  # 최대 15도 회전\n",
    "                    A.RandomBrightnessContrast(p=0.2),  # 밝기 및 대비 무작위 조정\n",
    "                ] + common_transforms\n",
    "            )\n",
    "        else:\n",
    "            # 검증/테스트용 변환: 공통 변환만 적용\n",
    "            self.transform = A.Compose(common_transforms)\n",
    "\n",
    "    def __call__(self, image) -> torch.Tensor:\n",
    "        # 이미지가 NumPy 배열인지 확인\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            raise TypeError(\"Image should be a NumPy array (OpenCV format).\")\n",
    "        \n",
    "        # 이미지에 변환 적용 및 결과 반환\n",
    "        transformed = self.transform(image=image)  # 이미지에 설정된 변환을 적용\n",
    "        \n",
    "        return transformed['image']  # 변환된 이미지의 텐서를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e82f3416-86f2-430f-9260-d23904e757e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformSelector:\n",
    "    \"\"\"\n",
    "    이미지 변환 라이브러리를 선택하기 위한 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(self, transform_type: str):\n",
    "\n",
    "        # 지원하는 변환 라이브러리인지 확인\n",
    "        if transform_type in [\"torchvision\", \"albumentations\"]:\n",
    "            self.transform_type = transform_type\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Unknown transformation library specified.\")\n",
    "\n",
    "    def get_transform(self, is_train: bool):\n",
    "        \n",
    "        # 선택된 라이브러리에 따라 적절한 변환 객체를 생성\n",
    "        if self.transform_type == 'torchvision':\n",
    "            transform = TorchvisionTransform(is_train=is_train)\n",
    "        \n",
    "        elif self.transform_type == 'albumentations':\n",
    "            transform = AlbumentationsTransform(is_train=is_train)\n",
    "        \n",
    "        return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c938bcb2-9257-49cb-8d05-dd4a7bb25665",
   "metadata": {},
   "source": [
    "# Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f16fb24a-8d34-4ed6-8a33-2d153d12d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    간단한 CNN 아키텍처를 정의하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        # 순전파 함수 정의\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f91493ca-c5c2-4950-916a-cc4304c7ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchvisionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Torchvision에서 제공하는 사전 훈련된 모델을 사용하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name: str, \n",
    "        num_classes: int, \n",
    "        pretrained: bool\n",
    "    ):\n",
    "        super(TorchvisionModel, self).__init__()\n",
    "        self.model = models.__dict__[model_name](pretrained=pretrained)\n",
    "        \n",
    "        # 모델의 최종 분류기 부분을 사용자 정의 클래스 수에 맞게 조정\n",
    "        if 'fc' in dir(self.model):\n",
    "            num_ftrs = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        \n",
    "        elif 'classifier' in dir(self.model):\n",
    "            num_ftrs = self.model.classifier[-1].in_features\n",
    "            self.model.classifier[-1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f28c8e4f-a914-4b12-982e-d4a58863c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimmModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Timm 라이브러리를 사용하여 다양한 사전 훈련된 모델을 제공하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name: str, \n",
    "        num_classes: int, \n",
    "        pretrained: bool\n",
    "    ):\n",
    "        super(TimmModel, self).__init__()\n",
    "        self.model = timm.create_model(\n",
    "            model_name, \n",
    "            pretrained=pretrained, \n",
    "            num_classes=num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f2da081-9010-431d-a049-835d7bbea4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSelector:\n",
    "    \"\"\"\n",
    "    사용할 모델 유형을 선택하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_type: str, \n",
    "        num_classes: int, \n",
    "        **kwargs\n",
    "    ):\n",
    "        \n",
    "        # 모델 유형에 따라 적절한 모델 객체를 생성\n",
    "        if model_type == 'simple':\n",
    "            self.model = SimpleCNN(num_classes=num_classes)\n",
    "        \n",
    "        elif model_type == 'torchvision':\n",
    "            self.model = TorchvisionModel(num_classes=num_classes, **kwargs)\n",
    "        \n",
    "        elif model_type == 'timm':\n",
    "            self.model = TimmModel(num_classes=num_classes, **kwargs)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Unknown model type specified.\")\n",
    "\n",
    "    def get_model(self) -> nn.Module:\n",
    "\n",
    "        # 생성된 모델 객체 반환\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2977c7b-bc39-48f7-8155-ef6b6a03d6f8",
   "metadata": {},
   "source": [
    "# Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "657800d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asymmetric Loss 정의 (다중 클래스 분류에 맞게 수정)\n",
    "class AsymmetricLoss(nn.Module):\n",
    "    def __init__(self, gamma_pos=1, gamma_neg=4, clip=0.05, eps=1e-8, reduction='mean'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            gamma_pos (float): 양성 클래스에 대한 초점 맞추기 파라미터.\n",
    "            gamma_neg (float): 음성 클래스에 대한 초점 맞추기 파라미터.\n",
    "            clip (float): 음성 예측에 대한 임계값.\n",
    "            eps (float): 로그 함수의 안정성을 위한 작은 값.\n",
    "            reduction (str): 손실의 합산 방식 ('mean' | 'sum' | 'none').\n",
    "        \"\"\"\n",
    "        super(AsymmetricLoss, self).__init__()\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.clip = clip\n",
    "        self.eps = eps\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: 모델의 출력 logits (batch_size, num_classes).\n",
    "            targets: 실제 정답 라벨 (batch_size).\n",
    "        \"\"\"\n",
    "        # 소프트맥스 확률 계산\n",
    "        probs = F.softmax(inputs, dim=1)  # (batch_size, num_classes)\n",
    "        \n",
    "        # 정답 클래스에 대한 확률 추출\n",
    "        targets_one_hot = F.one_hot(targets, num_classes=inputs.size(1))  # (batch_size, num_classes)\n",
    "        targets_one_hot = targets_one_hot.type_as(probs)\n",
    "        p_t = (probs * targets_one_hot).sum(dim=1)  # (batch_size)\n",
    "        \n",
    "        # 양성 클래스 손실 계산\n",
    "        loss_pos = -((1 - p_t) ** self.gamma_pos) * torch.log(p_t + self.eps)\n",
    "        \n",
    "        # 음성 클래스 손실 계산\n",
    "        p_n = (probs * (1 - targets_one_hot)).sum(dim=1)  # (batch_size)\n",
    "        loss_neg = -((p_n) ** self.gamma_neg) * torch.log(1 - p_n + self.eps)\n",
    "        \n",
    "        # 비대칭 손실 합산\n",
    "        loss = loss_pos + loss_neg\n",
    "\n",
    "        # 손실 합산 방식\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97471eb3-a979-4fb3-b976-6c3177c79f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    \"\"\"\n",
    "    모델의 손실함수를 계산하는 클래스. 현재 AsymmetricLoss를 사용하도록 설정.\n",
    "    \"\"\"\n",
    "    def __init__(self, loss_type='asymmetric'):\n",
    "        super(Loss, self).__init__()\n",
    "        if loss_type == 'cross_entropy':\n",
    "            self.loss_fn = nn.CrossEntropyLoss()\n",
    "        elif loss_type == 'asymmetric':\n",
    "            self.loss_fn = AsymmetricLoss(gamma_pos=1, gamma_neg=4, clip=0.05, reduction='mean')\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported loss type.\")\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        outputs: torch.Tensor, \n",
    "        targets: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        return self.loss_fn(outputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e3d21-5ab8-41b0-aa5c-e62ace8dc6a6",
   "metadata": {},
   "source": [
    "# Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "645626ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0.001):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): 개선이 없을 때 몇 에포크를 기다릴지\n",
    "            min_delta (float): 성능이 개선되었다고 판단하는 최소 변화량\n",
    "        \"\"\"\n",
    "        self.patience = patience  # 개선되지 않아도 기다리는 최대 에포크 수\n",
    "        self.min_delta = min_delta  # 성능 개선이 없다고 판단하는 최소 변화량\n",
    "        self.counter = 0  # 개선되지 않은 에포크 수 카운트\n",
    "        self.best_loss = None  # 검증 손실의 최저값\n",
    "        self.early_stop = False  # 중지 플래그\n",
    "    \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss  # 첫 번째 에포크의 손실 저장\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss  # 손실이 개선되면 갱신\n",
    "            self.counter = 0  # 카운터 초기화\n",
    "        else:\n",
    "            self.counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True  # patience를 초과하면 학습 중지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a90c673-6672-4066-a9ec-9975d7842be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler  # Mixed precision\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: nn.Module, \n",
    "        device: torch.device, \n",
    "        train_loader: DataLoader, \n",
    "        val_loader: DataLoader, \n",
    "        optimizer: optim.Optimizer,\n",
    "        scheduler: optim.lr_scheduler._LRScheduler,\n",
    "        loss_fn: torch.nn.modules.loss._Loss, \n",
    "        epochs: int,\n",
    "        result_path: str,\n",
    "        fold_idx: int,  # 폴드 인덱스 추가\n",
    "        patience: int = 3,  # Early Stopping patience 조정\n",
    "        min_delta: float = 0.001  # Early Stopping min_delta 조정\n",
    "    ):\n",
    "        # 클래스 초기화: 모델, 디바이스, 데이터 로더 등 설정\n",
    "        self.model = model  # 훈련할 모델\n",
    "        self.device = device  # 연산을 수행할 디바이스 (CPU or GPU)\n",
    "        self.train_loader = train_loader  # 훈련 데이터 로더\n",
    "        self.val_loader = val_loader  # 검증 데이터 로더\n",
    "        self.optimizer = optimizer  # 최적화 알고리즘\n",
    "        self.scheduler = scheduler  # 학습률 스케줄러\n",
    "        self.loss_fn = loss_fn  # 손실 함수\n",
    "        self.epochs = epochs  # 총 훈련 에폭 수\n",
    "        self.result_path = result_path  # 모델 저장 경로\n",
    "        self.fold_idx = fold_idx  # 현재 폴드 인덱스 저장\n",
    "        self.best_models = []  # 가장 좋은 상위 3개 모델의 정보를 저장할 리스트\n",
    "        self.lowest_loss = float('inf')  # 가장 낮은 Loss를 저장할 변수\n",
    "        self.early_stopping = EarlyStopping(patience=patience, min_delta=min_delta)  # EarlyStopping 초기화\n",
    "\n",
    "    def save_model(self, epoch, loss):\n",
    "        # 모델 저장 경로 설정\n",
    "        os.makedirs(self.result_path, exist_ok=True)\n",
    "\n",
    "        # 현재 에폭 모델 저장\n",
    "        current_model_path = os.path.join(\n",
    "            self.result_path, \n",
    "            f'fold_{self.fold_idx}_epoch_{epoch}_loss_{loss:.4f}.pt'\n",
    "        )\n",
    "        torch.save(self.model.state_dict(), current_model_path)\n",
    "\n",
    "        # 최상위 3개 모델 관리\n",
    "        self.best_models.append((loss, epoch, current_model_path))\n",
    "        self.best_models.sort()\n",
    "        if len(self.best_models) > 3:\n",
    "            _, _, path_to_remove = self.best_models.pop(-1)  # 가장 높은 손실 모델 삭제\n",
    "            if os.path.exists(path_to_remove):\n",
    "                os.remove(path_to_remove)\n",
    "\n",
    "        # 가장 낮은 손실의 모델 저장\n",
    "        if loss < self.lowest_loss:\n",
    "            self.lowest_loss = loss\n",
    "            best_model_path = os.path.join(self.result_path, f'fold_{self.fold_idx}_best_model.pt')\n",
    "            torch.save(self.model.state_dict(), best_model_path)\n",
    "            print(f\"Fold {self.fold_idx}: Save {epoch} epoch result. Loss = {loss:.4f}\")\n",
    "\n",
    "    def train_epoch(self) -> tuple:\n",
    "        # 한 에폭 동안의 훈련을 진행\n",
    "        self.model.train()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        progress_bar = tqdm(self.train_loader, desc=\"Training\", leave=False)\n",
    "        scaler = GradScaler()  # AMP를 위한 GradScaler 객체 생성\n",
    "\n",
    "        for images, targets in progress_bar:\n",
    "            images, targets = images.to(self.device), targets.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # autocast 컨텍스트 내에서 모델을 실행하여 정밀도를 관리\n",
    "            with autocast():\n",
    "                outputs = self.model(images)\n",
    "                loss = self.loss_fn(outputs, targets)\n",
    "\n",
    "            # 스케일링된 손실을 사용하여 역전파 실행\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # 스케일러를 사용해 가중치를 업데이트\n",
    "            scaler.step(self.optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 정확도 계산\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # 전체 정확도 계산\n",
    "        train_accuracy = 100.0 * correct / total\n",
    "        return total_loss / len(self.train_loader), train_accuracy\n",
    "\n",
    "    def validate(self) -> tuple:\n",
    "        # 모델의 검증을 진행\n",
    "        self.model.eval()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        progress_bar = tqdm(self.val_loader, desc=\"Validating\", leave=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, targets in progress_bar:\n",
    "                images, targets = images.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.loss_fn(outputs, targets)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # 정확도 계산\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "\n",
    "                progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # 전체 정확도 계산\n",
    "        val_accuracy = 100.0 * correct / total\n",
    "        return total_loss / len(self.val_loader), val_accuracy\n",
    "\n",
    "    def train(self) -> None:\n",
    "        # 전체 훈련 과정을 관리\n",
    "        for epoch in range(self.epochs):\n",
    "            print(f\"Epoch {epoch+1}/{self.epochs}\")\n",
    "\n",
    "            train_loss, train_accuracy = self.train_epoch()\n",
    "            val_loss, val_accuracy = self.validate()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "            print(f\"Epoch {epoch+1}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\\n\")\n",
    "\n",
    "            self.save_model(epoch, val_loss)\n",
    "\n",
    "            # Early Stopping 조건 확인\n",
    "            self.early_stopping(val_loss)\n",
    "            if self.early_stopping.early_stop:\n",
    "                print(\"Early stopping triggered. Stopping training...\")\n",
    "                break\n",
    "\n",
    "            self.scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f41c09-318a-4f2e-bdca-68d8a07e9938",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "698783c4-ac2a-4e66-82aa-637df06ce012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용할 장비를 선택.\n",
    "# torch라이브러리에서 gpu를 인식할 경우, cuda로 설정.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76cfe17e-fb14-42e4-84ae-b6773f0b78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터의 경로와 정보를 가진 파일의 경로를 설정.\n",
    "traindata_dir = \"/data/ephemeral/home/dog_remove/data/train\"\n",
    "traindata_info_file = \"/data/ephemeral/home/dog_remove/data/train_cleaned2.csv\"\n",
    "save_result_path = \"/data/ephemeral/home/youngtae/model2/Asymmmetric_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42a4778f-bfd0-4638-8972-f366cd6b0a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터의 class, image path, target에 대한 정보가 들어있는 csv파일을 읽기.\n",
    "train_info = pd.read_csv(traindata_info_file)\n",
    "\n",
    "# 총 class의 수를 측정.\n",
    "num_classes = len(train_info['target'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d675806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold 설정\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0889892-5f63-4dcf-bcab-9ff2659ad28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.0688, Train Accuracy: 77.40%\n",
      "Epoch 1, Validation Loss: 0.6969, Validation Accuracy: 87.33%\n",
      "\n",
      "Fold 1: Save 0 epoch result. Loss = 0.6969\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.4130, Train Accuracy: 91.00%\n",
      "Epoch 2, Validation Loss: 0.5514, Validation Accuracy: 89.10%\n",
      "\n",
      "Fold 1: Save 1 epoch result. Loss = 0.5514\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2371, Train Accuracy: 94.07%\n",
      "Epoch 3, Validation Loss: 0.5181, Validation Accuracy: 90.03%\n",
      "\n",
      "Fold 1: Save 2 epoch result. Loss = 0.5181\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1562, Train Accuracy: 95.59%\n",
      "Epoch 4, Validation Loss: 0.4446, Validation Accuracy: 90.46%\n",
      "\n",
      "Fold 1: Save 3 epoch result. Loss = 0.4446\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1111, Train Accuracy: 96.72%\n",
      "Epoch 5, Validation Loss: 0.4553, Validation Accuracy: 91.96%\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.0851, Train Accuracy: 97.86%\n",
      "Epoch 6, Validation Loss: 0.4296, Validation Accuracy: 91.70%\n",
      "\n",
      "Fold 1: Save 5 epoch result. Loss = 0.4296\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.0522, Train Accuracy: 98.37%\n",
      "Epoch 7, Validation Loss: 0.4262, Validation Accuracy: 92.26%\n",
      "\n",
      "Fold 1: Save 6 epoch result. Loss = 0.4262\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.0463, Train Accuracy: 98.77%\n",
      "Epoch 8, Validation Loss: 0.4268, Validation Accuracy: 92.00%\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.0337, Train Accuracy: 98.97%\n",
      "Epoch 9, Validation Loss: 0.4269, Validation Accuracy: 92.20%\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.0254, Train Accuracy: 99.14%\n",
      "Epoch 10, Validation Loss: 0.4295, Validation Accuracy: 92.20%\n",
      "\n",
      "Early stopping triggered. Stopping training...\n",
      "Fold 2\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.0843, Train Accuracy: 77.10%\n",
      "Epoch 1, Validation Loss: 0.7311, Validation Accuracy: 86.23%\n",
      "\n",
      "Fold 2: Save 0 epoch result. Loss = 0.7311\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.4185, Train Accuracy: 91.04%\n",
      "Epoch 2, Validation Loss: 0.5319, Validation Accuracy: 88.73%\n",
      "\n",
      "Fold 2: Save 1 epoch result. Loss = 0.5319\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2475, Train Accuracy: 93.57%\n",
      "Epoch 3, Validation Loss: 0.4858, Validation Accuracy: 90.33%\n",
      "\n",
      "Fold 2: Save 2 epoch result. Loss = 0.4858\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1632, Train Accuracy: 95.41%\n",
      "Epoch 4, Validation Loss: 0.4614, Validation Accuracy: 90.96%\n",
      "\n",
      "Fold 2: Save 3 epoch result. Loss = 0.4614\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1167, Train Accuracy: 96.58%\n",
      "Epoch 5, Validation Loss: 0.4365, Validation Accuracy: 91.36%\n",
      "\n",
      "Fold 2: Save 4 epoch result. Loss = 0.4365\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.0835, Train Accuracy: 97.67%\n",
      "Epoch 6, Validation Loss: 0.4088, Validation Accuracy: 92.30%\n",
      "\n",
      "Fold 2: Save 5 epoch result. Loss = 0.4088\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.0596, Train Accuracy: 98.42%\n",
      "Epoch 7, Validation Loss: 0.4014, Validation Accuracy: 92.60%\n",
      "\n",
      "Fold 2: Save 6 epoch result. Loss = 0.4014\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.0386, Train Accuracy: 98.78%\n",
      "Epoch 8, Validation Loss: 0.3944, Validation Accuracy: 92.83%\n",
      "\n",
      "Fold 2: Save 7 epoch result. Loss = 0.3944\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.0395, Train Accuracy: 98.81%\n",
      "Epoch 9, Validation Loss: 0.3966, Validation Accuracy: 92.93%\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.0339, Train Accuracy: 99.01%\n",
      "Epoch 10, Validation Loss: 0.3961, Validation Accuracy: 93.00%\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train Loss: nan, Train Accuracy: 96.65%\n",
      "Epoch 11, Validation Loss: 0.5556, Validation Accuracy: 90.46%\n",
      "\n",
      "Early stopping triggered. Stopping training...\n",
      "Fold 3\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: nan, Train Accuracy: 77.12%\n",
      "Epoch 1, Validation Loss: 0.8115, Validation Accuracy: 86.00%\n",
      "\n",
      "Fold 3: Save 0 epoch result. Loss = 0.8115\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.4159, Train Accuracy: 90.96%\n",
      "Epoch 2, Validation Loss: 0.6416, Validation Accuracy: 88.43%\n",
      "\n",
      "Fold 3: Save 1 epoch result. Loss = 0.6416\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2271, Train Accuracy: 94.21%\n",
      "Epoch 3, Validation Loss: 0.5462, Validation Accuracy: 89.86%\n",
      "\n",
      "Fold 3: Save 2 epoch result. Loss = 0.5462\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1584, Train Accuracy: 95.56%\n",
      "Epoch 4, Validation Loss: 0.5811, Validation Accuracy: 89.56%\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1177, Train Accuracy: 96.68%\n",
      "Epoch 5, Validation Loss: 0.5174, Validation Accuracy: 90.56%\n",
      "\n",
      "Fold 3: Save 4 epoch result. Loss = 0.5174\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.0714, Train Accuracy: 97.84%\n",
      "Epoch 6, Validation Loss: 0.5099, Validation Accuracy: 90.70%\n",
      "\n",
      "Fold 3: Save 5 epoch result. Loss = 0.5099\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.0607, Train Accuracy: 98.35%\n",
      "Epoch 7, Validation Loss: 0.4934, Validation Accuracy: 91.10%\n",
      "\n",
      "Fold 3: Save 6 epoch result. Loss = 0.4934\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.0449, Train Accuracy: 98.69%\n",
      "Epoch 8, Validation Loss: 0.4955, Validation Accuracy: 91.46%\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.0291, Train Accuracy: 99.12%\n",
      "Epoch 9, Validation Loss: 0.4898, Validation Accuracy: 91.23%\n",
      "\n",
      "Fold 3: Save 8 epoch result. Loss = 0.4898\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.0285, Train Accuracy: 99.03%\n",
      "Epoch 10, Validation Loss: 0.4909, Validation Accuracy: 91.33%\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train Loss: nan, Train Accuracy: 96.24%\n",
      "Epoch 11, Validation Loss: 0.7025, Validation Accuracy: 88.96%\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 0.2235, Train Accuracy: 95.12%\n",
      "Epoch 12, Validation Loss: 0.6145, Validation Accuracy: 90.00%\n",
      "\n",
      "Early stopping triggered. Stopping training...\n",
      "Fold 4\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.0596, Train Accuracy: 77.66%\n",
      "Epoch 1, Validation Loss: 0.7965, Validation Accuracy: 86.42%\n",
      "\n",
      "Fold 4: Save 0 epoch result. Loss = 0.7965\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.3957, Train Accuracy: 91.02%\n",
      "Epoch 2, Validation Loss: 0.5528, Validation Accuracy: 88.59%\n",
      "\n",
      "Fold 4: Save 1 epoch result. Loss = 0.5528\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2529, Train Accuracy: 93.92%\n",
      "Epoch 3, Validation Loss: 0.5714, Validation Accuracy: 89.43%\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1593, Train Accuracy: 95.81%\n",
      "Epoch 4, Validation Loss: 0.5291, Validation Accuracy: 90.46%\n",
      "\n",
      "Fold 4: Save 3 epoch result. Loss = 0.5291\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1187, Train Accuracy: 96.82%\n",
      "Epoch 5, Validation Loss: 0.4854, Validation Accuracy: 91.26%\n",
      "\n",
      "Fold 4: Save 4 epoch result. Loss = 0.4854\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.0703, Train Accuracy: 97.86%\n",
      "Epoch 6, Validation Loss: 0.5200, Validation Accuracy: 91.09%\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.0688, Train Accuracy: 98.12%\n",
      "Epoch 7, Validation Loss: 0.4827, Validation Accuracy: 91.43%\n",
      "\n",
      "Fold 4: Save 6 epoch result. Loss = 0.4827\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.0442, Train Accuracy: 98.61%\n",
      "Epoch 8, Validation Loss: nan, Validation Accuracy: 91.33%\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.0405, Train Accuracy: 98.90%\n",
      "Epoch 9, Validation Loss: 0.4781, Validation Accuracy: 91.79%\n",
      "\n",
      "Fold 4: Save 8 epoch result. Loss = 0.4781\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.0279, Train Accuracy: 99.15%\n",
      "Epoch 10, Validation Loss: nan, Validation Accuracy: 91.63%\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train Loss: 0.1579, Train Accuracy: 96.43%\n",
      "Epoch 11, Validation Loss: 0.6213, Validation Accuracy: 90.06%\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 0.1894, Train Accuracy: 95.39%\n",
      "Epoch 12, Validation Loss: nan, Validation Accuracy: 89.56%\n",
      "\n",
      "Early stopping triggered. Stopping training...\n",
      "Fold 5\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.0788, Train Accuracy: 78.04%\n",
      "Epoch 1, Validation Loss: 0.7386, Validation Accuracy: 87.42%\n",
      "\n",
      "Fold 5: Save 0 epoch result. Loss = 0.7386\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.4159, Train Accuracy: 90.85%\n",
      "Epoch 2, Validation Loss: 0.5871, Validation Accuracy: 88.86%\n",
      "\n",
      "Fold 5: Save 1 epoch result. Loss = 0.5871\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2344, Train Accuracy: 94.26%\n",
      "Epoch 3, Validation Loss: 0.5167, Validation Accuracy: 91.06%\n",
      "\n",
      "Fold 5: Save 2 epoch result. Loss = 0.5167\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1603, Train Accuracy: 95.66%\n",
      "Epoch 4, Validation Loss: 0.5259, Validation Accuracy: 90.93%\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1085, Train Accuracy: 97.17%\n",
      "Epoch 5, Validation Loss: 0.4754, Validation Accuracy: 90.99%\n",
      "\n",
      "Fold 5: Save 4 epoch result. Loss = 0.4754\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.0796, Train Accuracy: 97.57%\n",
      "Epoch 6, Validation Loss: 0.4894, Validation Accuracy: 91.46%\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.0613, Train Accuracy: 98.21%\n",
      "Epoch 7, Validation Loss: 0.4595, Validation Accuracy: 91.96%\n",
      "\n",
      "Fold 5: Save 6 epoch result. Loss = 0.4595\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.0463, Train Accuracy: 98.74%\n",
      "Epoch 8, Validation Loss: 0.4616, Validation Accuracy: 92.09%\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.0266, Train Accuracy: 99.03%\n",
      "Epoch 9, Validation Loss: 0.4681, Validation Accuracy: 92.33%\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.0373, Train Accuracy: 99.07%\n",
      "Epoch 10, Validation Loss: 0.4687, Validation Accuracy: 92.49%\n",
      "\n",
      "Early stopping triggered. Stopping training...\n"
     ]
    }
   ],
   "source": [
    "for fold_idx, (train_index, val_index) in enumerate(skf.split(train_info, train_info['target']), 1):\n",
    "    print(f'Fold {fold_idx}')\n",
    "\n",
    "    # 각 폴드에 따라 데이터 분리\n",
    "    train_df = train_info.iloc[train_index].reset_index(drop=True)\n",
    "    val_df = train_info.iloc[val_index].reset_index(drop=True)\n",
    "\n",
    "    # Transform 설정\n",
    "    transform_selector = TransformSelector(\n",
    "        transform_type=\"torchvision\"  # \"torchvision\" 또는 \"albumentations\"\n",
    "    )\n",
    "    train_transform = transform_selector.get_transform(is_train=True)\n",
    "    val_transform = transform_selector.get_transform(is_train=False)\n",
    "\n",
    "    # Dataset 생성\n",
    "    train_dataset = CustomDataset(\n",
    "        root_dir=traindata_dir,\n",
    "        info_df=train_df,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    val_dataset = CustomDataset(\n",
    "        root_dir=traindata_dir,\n",
    "        info_df=val_df,\n",
    "        transform=val_transform\n",
    "    )\n",
    "\n",
    "    # DataLoader에서 worker_init_fn을 설정하여 각 워커의 시드를 고정\n",
    "    def worker_init_fn(worker_id):\n",
    "        np.random.seed(seed + worker_id)\n",
    "        random.seed(seed + worker_id)\n",
    "\n",
    "    # DataLoader 생성\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=64, \n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=worker_init_fn\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=64, \n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=worker_init_fn\n",
    "    )\n",
    "\n",
    "    # 학습에 사용할 Model을 선언합니다.\n",
    "    model_selector = ModelSelector(\n",
    "        model_type='timm', \n",
    "        num_classes=num_classes,\n",
    "        model_name='eva02_large_patch14_448.mim_m38m_ft_in22k_in1k', \n",
    "        pretrained=True\n",
    "    )\n",
    "    model = model_selector.get_model()\n",
    "\n",
    "    # 선언된 모델을 학습에 사용할 장비로 셋팅합니다.\n",
    "    model.to(device)\n",
    "\n",
    "    # 모델의 모든 파라미터를 동결 (학습되지 않도록 설정)\n",
    "    for name, param in model.named_parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # 마지막 레이어와 그 전 레이어만 학습되도록 설정\n",
    "    # 여기서는 'blocks.22', 'blocks.23', 'head'를 예시로 들었습니다.\n",
    "    # 실제 모델 구조에 따라 레이어 이름을 확인하고 수정해야 합니다.\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'blocks.23' in name or 'blocks.22' in name or 'head' in name:\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # 옵티마이저 설정: 레이어별로 다른 학습률 적용\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            'params': [p for n, p in model.named_parameters() if ('blocks.23' not in n and 'blocks.22' not in n and 'head' not in n) and p.requires_grad],\n",
    "            'lr': 1e-5,  # 그 전 레이어는 낮은 학습률\n",
    "            'weight_decay': 1e-4\n",
    "        },\n",
    "        {\n",
    "            'params': [p for n, p in model.named_parameters() if ('blocks.23' in n or 'blocks.22' in n) and p.requires_grad],\n",
    "            'lr': 1e-4,  # penultimate 레이어는 중간 학습률\n",
    "            'weight_decay': 1e-4\n",
    "        },\n",
    "        {\n",
    "            'params': [p for n, p in model.named_parameters() if 'head' in n and p.requires_grad],\n",
    "            'lr': 1e-3,  # head 레이어는 높은 학습률\n",
    "            'weight_decay': 1e-4\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    optimizer = optim.AdamW(\n",
    "        optimizer_grouped_parameters\n",
    "    )\n",
    "\n",
    "    # 스케줄러 초기화: Cosine Annealing with Warm Restarts 적용\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, \n",
    "        T_0=10,  # 첫 번째 주기 (에포크 수)\n",
    "        T_mult=1,  # 주기 증가 배수 (여기서는 고정)\n",
    "        eta_min=1e-6  # 최저 학습률\n",
    "    )\n",
    "\n",
    "    # 학습에 사용할 Loss를 선언 (AsymmetricLoss 사용)\n",
    "    loss_fn = Loss(loss_type='asymmetric')\n",
    "\n",
    "    # 결과 저장 경로 수정\n",
    "    fold_result_path = os.path.join(save_result_path, f'fold_{fold_idx}')\n",
    "    os.makedirs(fold_result_path, exist_ok=True)\n",
    "\n",
    "    # Trainer 선언\n",
    "    trainer = Trainer(\n",
    "        model=model, \n",
    "        device=device, \n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader, \n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        loss_fn=loss_fn, \n",
    "        epochs=100,\n",
    "        result_path=fold_result_path,\n",
    "        fold_idx=fold_idx  # 폴드 인덱스 전달\n",
    "    )\n",
    "\n",
    "    # 모델 학습.\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11087088-9b1f-4f7d-8eb5-72008cc88a50",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6bf92c3c-7b38-4f89-af2a-5dfbabf51926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_inference_tta(\n",
    "    models: List[nn.Module], \n",
    "    device: torch.device, \n",
    "    test_loader: DataLoader,\n",
    "    base_transform: Callable,\n",
    "    tta_transform: Callable,\n",
    "    tta_steps: int = 3  # 메모리 부담을 줄이기 위해 TTA 단계 줄이기\n",
    "):\n",
    "    \"\"\"\n",
    "    Test Time Augmentation (TTA)을 적용한 추론 함수.\n",
    "    \n",
    "    Args:\n",
    "        models (List[nn.Module]): 앙상블할 학습된 모델 리스트.\n",
    "        device (torch.device): 연산을 수행할 디바이스.\n",
    "        test_loader (DataLoader): 테스트 데이터 로더.\n",
    "        base_transform (Callable): 기본 변환 함수.\n",
    "        tta_transform (Callable): TTA를 위한 변환 함수.\n",
    "        tta_steps (int): TTA 증강 횟수.\n",
    "    \n",
    "    Returns:\n",
    "        List[int]: 예측된 클래스 인덱스 리스트.\n",
    "    \"\"\"\n",
    "    if not models:\n",
    "        raise ValueError(\"The models list is empty. Please load at least one model before inference.\")\n",
    "    \n",
    "    for model_idx, model in enumerate(models, 1):\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        print(f\"Model {model_idx} loaded and set to eval mode.\")\n",
    "    \n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, images in enumerate(tqdm(test_loader, desc=\"TTA Inference\")):\n",
    "            # images는 PIL 이미지 리스트\n",
    "            B = len(images)\n",
    "            \n",
    "            # 변수 초기화\n",
    "            base_images = None\n",
    "            sum_probs = None\n",
    "            logits = None\n",
    "            probs = None\n",
    "            avg_probs = None\n",
    "            tta_transformed = None\n",
    "            \n",
    "            try:\n",
    "                # 기본 변환 적용\n",
    "                base_images = torch.stack([base_transform(image) for image in images]).to(device)\n",
    "                # 확률을 누적할 텐서 초기화\n",
    "                sum_probs = torch.zeros(B, num_classes).to(device)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in base_transform at batch {batch_idx}: {e}\")\n",
    "                continue  # 다음 배치로 넘어갑니다.\n",
    "            \n",
    "            for model_idx, model in enumerate(models, 1):\n",
    "                try:\n",
    "                    # 기본 이미지 예측\n",
    "                    logits = model(base_images)\n",
    "                    probs = F.softmax(logits, dim=1)\n",
    "                    sum_probs += probs\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in model {model_idx} during base image inference: {e}\")\n",
    "                    continue  # 다음 모델로 넘어갑니다.\n",
    "                \n",
    "                for step in range(tta_steps):\n",
    "                    try:\n",
    "                        # TTA 변환 적용\n",
    "                        tta_transformed = torch.stack([tta_transform(image) for image in images]).to(device)\n",
    "                        logits = model(tta_transformed)\n",
    "                        probs = F.softmax(logits, dim=1)\n",
    "                        sum_probs += probs / tta_steps  # TTA 확률을 평균으로 반영\n",
    "                        # 메모리 해제\n",
    "                        del tta_transformed, logits, probs\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error in model {model_idx} during TTA step {step+1}: {e}\")\n",
    "                        continue  # 다음 TTA 단계로 넘어갑니다.\n",
    "            \n",
    "            try:\n",
    "                # 모델 수로 나누어 평균 확률 계산\n",
    "                avg_probs = sum_probs / len(models)\n",
    "                \n",
    "                # 예측 클래스 결정 (Top-1)\n",
    "                preds = avg_probs.argmax(dim=1)\n",
    "                predictions.extend(preds.cpu().numpy())\n",
    "            except Exception as e:\n",
    "                print(f\"Error during probability averaging or prediction at batch {batch_idx}: {e}\")\n",
    "                continue  # 다음 배치로 넘어갑니다.\n",
    "            \n",
    "            # 메모리 해제\n",
    "            variables_to_del = ['base_images', 'sum_probs', 'logits', 'probs', 'avg_probs']\n",
    "            for var in variables_to_del:\n",
    "                try:\n",
    "                    del globals()[var]\n",
    "                except KeyError:\n",
    "                    try:\n",
    "                        del locals()[var]\n",
    "                    except KeyError:\n",
    "                        pass  # 변수가 존재하지 않으면 무시합니다.\n",
    "            torch.cuda.empty_cache()  # 캐시 비우기\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b407c24c-785d-4ffc-b17b-84ae7dc4ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 데이터의 경로와 정보를 가진 파일의 경로를 설정.\n",
    "testdata_dir = \"/data/ephemeral/home/dog_remove/data/test\"\n",
    "testdata_info_file = \"/data/ephemeral/home/dog_remove/data/test.csv\"\n",
    "save_result_path = \"/data/ephemeral/home/youngtae/model2/Asymmmetric_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cbb89c12-3b5d-4647-a8c2-83650dce6281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 데이터의 class, image path, target에 대한 정보가 들어있는 csv파일을 읽기.\n",
    "test_info = pd.read_csv(testdata_info_file)\n",
    "\n",
    "# 총 class 수.\n",
    "num_classes = len(train_info['target'].unique())  # 일관성 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ecec8773-6045-401e-b307-0a9758374c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론에 사용할 Dataset을 선언.\n",
    "test_dataset = CustomDataset(\n",
    "    root_dir=testdata_dir,\n",
    "    info_df=test_info,\n",
    "    transform=None,  # 변환은 직접 적용\n",
    "    is_inference=True\n",
    ")\n",
    "# DataLoader에서 worker_init_fn을 설정하여 각 워커의 시드를 고정\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(seed + worker_id)\n",
    "    random.seed(seed + worker_id)\n",
    "\n",
    "# 추론에 사용할 DataLoader를 선언합니다.\n",
    "# 배치 크기와 TTA 단계를 줄여 메모리 사용량 감소\n",
    "batch_size = 16  # 배치 크기 감소\n",
    "tta_steps = 3    # TTA 단계 감소\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    worker_init_fn=worker_init_fn,\n",
    "    collate_fn=lambda x: x  # PIL 이미지 리스트 반환\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99cc06c1-ce65-476b-8d5b-b8025fcde443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앙상블할 모델들을 저장할 리스트\n",
    "models = []\n",
    "\n",
    "# 각 폴드의 모델을 불러오기\n",
    "for fold_idx in range(1, n_splits + 1):\n",
    "    # 모델 초기화\n",
    "    model_selector = ModelSelector(\n",
    "        model_type='timm', \n",
    "        num_classes=num_classes,\n",
    "        model_name='eva02_large_patch14_448.mim_m38m_ft_in22k_in1k', \n",
    "        pretrained=False\n",
    "    )\n",
    "    model = model_selector.get_model()\n",
    "\n",
    "    # 모델의 모든 파라미터를 동결 (학습되지 않도록 설정)\n",
    "    for name, param in model.named_parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # 마지막 레이어와 그 전 레이어만 학습되도록 설정\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'blocks.23' in name or 'blocks.22' in name or 'head' in name:\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # 모델 가중치 로드\n",
    "    fold_result_path = os.path.join(save_result_path, f'fold_{fold_idx}')\n",
    "    model_path = os.path.join(fold_result_path, f'fold_{fold_idx}_best_model.pt')\n",
    "    model.load_state_dict(\n",
    "        torch.load(\n",
    "            model_path,\n",
    "            map_location=device\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 모델을 리스트에 추가\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d4c4219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA를 포함한 앙상블 추론 함수 호출\n",
    "# 여기서 AutoAugment는 tta_transform에 포함되어 TTA 과정에서 적용됩니다.\n",
    "# base_transform과 tta_transform은 학습 시 사용한 것과 동일한 방식으로 정의해야 합니다.\n",
    "transform_selector = TransformSelector(transform_type=\"torchvision\")\n",
    "base_transform = transform_selector.get_transform(is_train=False)\n",
    "tta_transform = transform_selector.get_transform(is_train=True)  # TTA는 훈련 시 변환과 동일하게 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "514852af-f338-4b27-a5a5-8b65406a8023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 loaded and set to eval mode.\n",
      "Model 2 loaded and set to eval mode.\n",
      "Model 3 loaded and set to eval mode.\n",
      "Model 4 loaded and set to eval mode.\n",
      "Model 5 loaded and set to eval mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Inference: 100%|██████████| 626/626 [3:42:50<00:00, 21.36s/it]  \n"
     ]
    }
   ],
   "source": [
    "predictions = ensemble_inference_tta(\n",
    "    models=models, \n",
    "    device=device, \n",
    "    test_loader=test_loader,\n",
    "    base_transform=base_transform,\n",
    "    tta_transform=tta_transform,  # TTA 변환에 AutoAugment가 포함됨\n",
    "    tta_steps=tta_steps  # TTA 증강 횟수\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc96c889-2423-42b2-8c3c-4b1d364ece71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과를 CSV 형식에 맞게 저장\n",
    "test_info['target'] = predictions\n",
    "test_info = test_info.reset_index().rename(columns={\"index\": \"ID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4efd2f6-d74a-491b-a7b1-fd7cf96f45a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "test_info.to_csv(\"Asymmetric.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac79e3df-e5c3-4a49-b37e-0dea1300c317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784addf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
