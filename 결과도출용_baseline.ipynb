{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af8a2c0-45fe-4d13-bebd-0dca87a7b71f",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c611c8-2226-433c-bf5f-343cc0b094af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리를 임포트합니다.\n",
    "import os\n",
    "from typing import Tuple, Callable, Union, List\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import timm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms import AutoAugment, AutoAugmentPolicy\n",
    "import albumentations as A\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f69e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 시드 설정 함수\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 시드 값 설정\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d69e6a-a719-4a97-92ca-6354c873313f",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56f97229-e29f-479d-abab-0db8219d1803",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        root_dir: str, \n",
    "        info_df: pd.DataFrame, \n",
    "        transform: Callable,\n",
    "        is_inference: bool = False\n",
    "    ):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_inference = is_inference\n",
    "        self.image_paths = info_df['image_path'].tolist()\n",
    "        \n",
    "        if not self.is_inference:\n",
    "            self.targets = info_df['target'].tolist()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Union[Tuple[torch.Tensor, int], torch.Tensor]:\n",
    "        img_path = os.path.join(self.root_dir, self.image_paths[index])\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "        \n",
    "        # Albumentations의 경우 NumPy 배열을 그대로 사용\n",
    "        if isinstance(self.transform, AlbumentationsTransform):\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # OpenCV로 읽은 이미지를 RGB로 변환\n",
    "            image = self.transform(image=image)             # Albumentations 변환 적용 (이미지 텐서 반환)\n",
    "        else:\n",
    "            # Torchvision의 경우 PIL Image로 변환하여 처리\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(image)\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.is_inference:\n",
    "            return image\n",
    "        else:\n",
    "            target = self.targets[index]\n",
    "            return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c07d2d0-9585-45ce-8ece-4f69b98f6dd4",
   "metadata": {},
   "source": [
    "# Transform Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1855c1-cf13-476d-aabd-d78e9e082ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchvisionTransform:\n",
    "    def __init__(self, is_train: bool = True):\n",
    "        common_transforms = [\n",
    "            transforms.Resize((448, 448)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "        \n",
    "        if is_train:\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    AutoAugment(policy=AutoAugmentPolicy.IMAGENET),\n",
    "                ] + common_transforms\n",
    "            )\n",
    "        else:\n",
    "            self.transform = transforms.Compose(common_transforms)\n",
    "\n",
    "    def __call__(self, image: Image.Image) -> torch.Tensor:\n",
    "        return self.transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a683988-0f73-4e43-907b-0d5209550abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlbumentationsTransform:\n",
    "    def __init__(self, is_train: bool = True):\n",
    "        # 공통 변환 설정: 이미지 리사이즈, 정규화, 텐서 변환\n",
    "        common_transforms = [\n",
    "            A.Resize(448, 448),  # 이미지를 224x224 크기로 리사이즈\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 정규화\n",
    "            ToTensorV2()  # albumentations에서 제공하는 PyTorch 텐서 변환\n",
    "        ]\n",
    "        \n",
    "        if is_train:\n",
    "            # 훈련용 변환: 랜덤 수평 뒤집기, 랜덤 회전, 랜덤 밝기 및 대비 조정 추가\n",
    "            self.transform = A.Compose(\n",
    "                [\n",
    "                    A.HorizontalFlip(p=0.5),  # 50% 확률로 이미지를 수평 뒤집기\n",
    "                    A.Rotate(limit=15),  # 최대 15도 회전\n",
    "                    A.RandomBrightnessContrast(p=0.2),  # 밝기 및 대비 무작위 조정\n",
    "                ] + common_transforms\n",
    "            )\n",
    "        else:\n",
    "            # 검증/테스트용 변환: 공통 변환만 적용\n",
    "            self.transform = A.Compose(common_transforms)\n",
    "\n",
    "    def __call__(self, image) -> torch.Tensor:\n",
    "        # 이미지가 NumPy 배열인지 확인\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            raise TypeError(\"Image should be a NumPy array (OpenCV format).\")\n",
    "        \n",
    "        # 이미지에 변환 적용 및 결과 반환\n",
    "        transformed = self.transform(image=image)  # 이미지에 설정된 변환을 적용\n",
    "        \n",
    "        return transformed['image']  # 변환된 이미지의 텐서를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e82f3416-86f2-430f-9260-d23904e757e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformSelector:\n",
    "    \"\"\"\n",
    "    이미지 변환 라이브러리를 선택하기 위한 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(self, transform_type: str):\n",
    "\n",
    "        # 지원하는 변환 라이브러리인지 확인\n",
    "        if transform_type in [\"torchvision\", \"albumentations\"]:\n",
    "            self.transform_type = transform_type\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Unknown transformation library specified.\")\n",
    "\n",
    "    def get_transform(self, is_train: bool):\n",
    "        \n",
    "        # 선택된 라이브러리에 따라 적절한 변환 객체를 생성\n",
    "        if self.transform_type == 'torchvision':\n",
    "            transform = TorchvisionTransform(is_train=is_train)\n",
    "        \n",
    "        elif self.transform_type == 'albumentations':\n",
    "            transform = AlbumentationsTransform(is_train=is_train)\n",
    "        \n",
    "        return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c938bcb2-9257-49cb-8d05-dd4a7bb25665",
   "metadata": {},
   "source": [
    "# Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f16fb24a-8d34-4ed6-8a33-2d153d12d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    간단한 CNN 아키텍처를 정의하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        # 순전파 함수 정의\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f91493ca-c5c2-4950-916a-cc4304c7ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchvisionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Torchvision에서 제공하는 사전 훈련된 모델을 사용하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name: str, \n",
    "        num_classes: int, \n",
    "        pretrained: bool\n",
    "    ):\n",
    "        super(TorchvisionModel, self).__init__()\n",
    "        self.model = models.__dict__[model_name](pretrained=pretrained)\n",
    "        \n",
    "        # 모델의 최종 분류기 부분을 사용자 정의 클래스 수에 맞게 조정\n",
    "        if 'fc' in dir(self.model):\n",
    "            num_ftrs = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        \n",
    "        elif 'classifier' in dir(self.model):\n",
    "            num_ftrs = self.model.classifier[-1].in_features\n",
    "            self.model.classifier[-1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f28c8e4f-a914-4b12-982e-d4a58863c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimmModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Timm 라이브러리를 사용하여 다양한 사전 훈련된 모델을 제공하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name: str, \n",
    "        num_classes: int, \n",
    "        pretrained: bool\n",
    "    ):\n",
    "        super(TimmModel, self).__init__()\n",
    "        self.model = timm.create_model(\n",
    "            model_name, \n",
    "            pretrained=pretrained, \n",
    "            num_classes=num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f2da081-9010-431d-a049-835d7bbea4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSelector:\n",
    "    \"\"\"\n",
    "    사용할 모델 유형을 선택하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_type: str, \n",
    "        num_classes: int, \n",
    "        **kwargs\n",
    "    ):\n",
    "        \n",
    "        # 모델 유형에 따라 적절한 모델 객체를 생성\n",
    "        if model_type == 'simple':\n",
    "            self.model = SimpleCNN(num_classes=num_classes)\n",
    "        \n",
    "        elif model_type == 'torchvision':\n",
    "            self.model = TorchvisionModel(num_classes=num_classes, **kwargs)\n",
    "        \n",
    "        elif model_type == 'timm':\n",
    "            self.model = TimmModel(num_classes=num_classes, **kwargs)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Unknown model type specified.\")\n",
    "\n",
    "    def get_model(self) -> nn.Module:\n",
    "\n",
    "        # 생성된 모델 객체 반환\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2977c7b-bc39-48f7-8155-ef6b6a03d6f8",
   "metadata": {},
   "source": [
    "# Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97471eb3-a979-4fb3-b976-6c3177c79f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    \"\"\"\n",
    "    모델의 손실함수를 계산하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Loss, self).__init__()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        outputs: torch.Tensor, \n",
    "        targets: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "    \n",
    "        return self.loss_fn(outputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e3d21-5ab8-41b0-aa5c-e62ace8dc6a6",
   "metadata": {},
   "source": [
    "# Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "645626ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): 개선이 없을 때 몇 에포크를 기다릴지\n",
    "            min_delta (float): 성능이 개선되었다고 판단하는 최소 변화량\n",
    "        \"\"\"\n",
    "        self.patience = patience  # 개선되지 않아도 기다리는 최대 에포크 수\n",
    "        self.min_delta = min_delta  # 성능 개선이 없다고 판단하는 최소 변화량\n",
    "        self.counter = 0  # 개선되지 않은 에포크 수 카운트\n",
    "        self.best_loss = None  # 검증 손실의 최저값\n",
    "        self.early_stop = False  # 중지 플래그\n",
    "    \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss  # 첫 번째 에포크의 손실 저장\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss  # 손실이 개선되면 갱신\n",
    "            self.counter = 0  # 카운터 초기화\n",
    "        else:\n",
    "            self.counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True  # patience를 초과하면 학습 중지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a90c673-6672-4066-a9ec-9975d7842be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler  # Mixed precision\n",
    "import os\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: nn.Module, \n",
    "        device: torch.device, \n",
    "        train_loader: DataLoader, \n",
    "        val_loader: DataLoader, \n",
    "        optimizer: optim.Optimizer,\n",
    "        scheduler: optim.lr_scheduler,\n",
    "        loss_fn: torch.nn.modules.loss._Loss, \n",
    "        epochs: int,\n",
    "        result_path: str,\n",
    "        fold_idx: int,  # 폴드 인덱스 추가\n",
    "        patience: int = 5,  # Early Stopping patience 추가\n",
    "        min_delta: float = 0.01  # Early Stopping min_delta 추가\n",
    "    ):\n",
    "        # 클래스 초기화: 모델, 디바이스, 데이터 로더 등 설정\n",
    "        self.model = model  # 훈련할 모델\n",
    "        self.device = device  # 연산을 수행할 디바이스 (CPU or GPU)\n",
    "        self.train_loader = train_loader  # 훈련 데이터 로더\n",
    "        self.val_loader = val_loader  # 검증 데이터 로더\n",
    "        self.optimizer = optimizer  # 최적화 알고리즘\n",
    "        self.scheduler = scheduler  # 학습률 스케줄러\n",
    "        self.loss_fn = loss_fn  # 손실 함수\n",
    "        self.epochs = epochs  # 총 훈련 에폭 수\n",
    "        self.result_path = result_path  # 모델 저장 경로\n",
    "        self.fold_idx = fold_idx  # 현재 폴드 인덱스 저장\n",
    "        self.best_models = []  # 가장 좋은 상위 3개 모델의 정보를 저장할 리스트\n",
    "        self.lowest_loss = float('inf')  # 가장 낮은 Loss를 저장할 변수\n",
    "        self.early_stopping = EarlyStopping(patience=patience, min_delta=min_delta)  # EarlyStopping 초기화\n",
    "\n",
    "    def save_model(self, epoch, loss):\n",
    "        # 모델 저장 경로 설정\n",
    "        os.makedirs(self.result_path, exist_ok=True)\n",
    "\n",
    "        # 현재 에폭 모델 저장\n",
    "        current_model_path = os.path.join(\n",
    "            self.result_path, \n",
    "            f'fold_{self.fold_idx}_epoch_{epoch}_loss_{loss:.4f}.pt'\n",
    "        )\n",
    "        torch.save(self.model.state_dict(), current_model_path)\n",
    "\n",
    "        # 최상위 3개 모델 관리\n",
    "        self.best_models.append((loss, epoch, current_model_path))\n",
    "        self.best_models.sort()\n",
    "        if len(self.best_models) > 3:\n",
    "            _, _, path_to_remove = self.best_models.pop(-1)  # 가장 높은 손실 모델 삭제\n",
    "            if os.path.exists(path_to_remove):\n",
    "                os.remove(path_to_remove)\n",
    "\n",
    "        # 가장 낮은 손실의 모델 저장\n",
    "        if loss < self.lowest_loss:\n",
    "            self.lowest_loss = loss\n",
    "            best_model_path = os.path.join(self.result_path, f'fold_{self.fold_idx}_best_model.pt')\n",
    "            torch.save(self.model.state_dict(), best_model_path)\n",
    "            print(f\"Fold {self.fold_idx}: Save {epoch} epoch result. Loss = {loss:.4f}\")\n",
    "\n",
    "    def train_epoch(self) -> tuple:\n",
    "        # 한 에폭 동안의 훈련을 진행\n",
    "        self.model.train()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        progress_bar = tqdm(self.train_loader, desc=\"Training\", leave=False)\n",
    "        scaler = GradScaler()  # AMP를 위한 GradScaler 객체 생성\n",
    "\n",
    "        for images, targets in progress_bar:\n",
    "            images, targets = images.to(self.device), targets.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # autocast 컨텍스트 내에서 모델을 실행하여 정밀도를 관리\n",
    "            with autocast():\n",
    "                outputs = self.model(images)\n",
    "                loss = self.loss_fn(outputs, targets)\n",
    "\n",
    "            # 스케일링된 손실을 사용하여 역전파 실행\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # 스케일러를 사용해 가중치를 업데이트\n",
    "            scaler.step(self.optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 정확도 계산\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # 전체 정확도 계산\n",
    "        train_accuracy = 100.0 * correct / total\n",
    "        return total_loss / len(self.train_loader), train_accuracy\n",
    "\n",
    "    def validate(self) -> tuple:\n",
    "        # 모델의 검증을 진행\n",
    "        self.model.eval()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        progress_bar = tqdm(self.val_loader, desc=\"Validating\", leave=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, targets in progress_bar:\n",
    "                images, targets = images.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.loss_fn(outputs, targets)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # 정확도 계산\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "\n",
    "                progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # 전체 정확도 계산\n",
    "        val_accuracy = 100.0 * correct / total\n",
    "        return total_loss / len(self.val_loader), val_accuracy\n",
    "\n",
    "    def train(self) -> None:\n",
    "        # 전체 훈련 과정을 관리\n",
    "        for epoch in range(self.epochs):\n",
    "            print(f\"Epoch {epoch+1}/{self.epochs}\")\n",
    "\n",
    "            train_loss, train_accuracy = self.train_epoch()\n",
    "            val_loss, val_accuracy = self.validate()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "            print(f\"Epoch {epoch+1}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\\n\")\n",
    "\n",
    "            self.save_model(epoch, val_loss)\n",
    "\n",
    "            # Early Stopping 조건 확인\n",
    "            self.early_stopping(val_loss)\n",
    "            if self.early_stopping.early_stop:\n",
    "                print(\"Early stopping triggered. Stopping training...\")\n",
    "                break\n",
    "\n",
    "            self.scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f41c09-318a-4f2e-bdca-68d8a07e9938",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "698783c4-ac2a-4e66-82aa-637df06ce012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용할 장비를 선택.\n",
    "# torch라이브러리에서 gpu를 인식할 경우, cuda로 설정.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76cfe17e-fb14-42e4-84ae-b6773f0b78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터의 경로와 정보를 가진 파일의 경로를 설정.\n",
    "traindata_dir = \"/data/ephemeral/home/data/train\"\n",
    "traindata_info_file = \"/data/ephemeral/home/data/train.csv\"\n",
    "save_result_path = \"/data/ephemeral/home/youngtae/model2/ensemble_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42a4778f-bfd0-4638-8972-f366cd6b0a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터의 class, image path, target에 대한 정보가 들어있는 csv파일을 읽기.\n",
    "train_info = pd.read_csv(traindata_info_file)\n",
    "\n",
    "# 총 class의 수를 측정.\n",
    "num_classes = len(train_info['target'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0889892-5f63-4dcf-bcab-9ff2659ad28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.1588, Train Accuracy: 78.00%\n",
      "Epoch 1, Validation Loss: 0.4467, Validation Accuracy: 88.59%\n",
      "\n",
      "Fold 1: Save 0 epoch result. Loss = 0.4467\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.3428, Train Accuracy: 90.14%\n",
      "Epoch 2, Validation Loss: 0.4134, Validation Accuracy: 89.42%\n",
      "\n",
      "Fold 1: Save 1 epoch result. Loss = 0.4134\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2299, Train Accuracy: 93.04%\n",
      "Epoch 3, Validation Loss: 0.4325, Validation Accuracy: 89.08%\n",
      "\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1887, Train Accuracy: 94.18%\n",
      "Epoch 4, Validation Loss: 0.4315, Validation Accuracy: 90.02%\n",
      "\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1664, Train Accuracy: 94.92%\n",
      "Epoch 5, Validation Loss: 0.3972, Validation Accuracy: 90.52%\n",
      "\n",
      "Fold 1: Save 4 epoch result. Loss = 0.3972\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.1424, Train Accuracy: 95.85%\n",
      "Epoch 6, Validation Loss: 0.4175, Validation Accuracy: 89.82%\n",
      "\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.1246, Train Accuracy: 96.35%\n",
      "Epoch 7, Validation Loss: 0.4264, Validation Accuracy: 90.28%\n",
      "\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1321, Train Accuracy: 96.20%\n",
      "Epoch 8, Validation Loss: 0.3989, Validation Accuracy: 90.98%\n",
      "\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.1147, Train Accuracy: 96.85%\n",
      "Epoch 9, Validation Loss: 0.4177, Validation Accuracy: 91.21%\n",
      "\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.0970, Train Accuracy: 96.98%\n",
      "Epoch 10, Validation Loss: 0.4329, Validation Accuracy: 90.95%\n",
      "\n",
      "Early stopping triggered. Stopping training...\n",
      "Fold 2\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.1606, Train Accuracy: 77.82%\n",
      "Epoch 1, Validation Loss: 0.5077, Validation Accuracy: 87.72%\n",
      "\n",
      "Fold 2: Save 0 epoch result. Loss = 0.5077\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.3277, Train Accuracy: 90.81%\n",
      "Epoch 2, Validation Loss: 0.4156, Validation Accuracy: 88.95%\n",
      "\n",
      "Fold 2: Save 1 epoch result. Loss = 0.4156\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2200, Train Accuracy: 93.42%\n",
      "Epoch 3, Validation Loss: 0.4397, Validation Accuracy: 89.48%\n",
      "\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1754, Train Accuracy: 94.86%\n",
      "Epoch 4, Validation Loss: 0.4074, Validation Accuracy: 90.28%\n",
      "\n",
      "Fold 2: Save 3 epoch result. Loss = 0.4074\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1538, Train Accuracy: 95.13%\n",
      "Epoch 5, Validation Loss: 0.4183, Validation Accuracy: 89.91%\n",
      "\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.1322, Train Accuracy: 96.10%\n",
      "Epoch 6, Validation Loss: 0.4260, Validation Accuracy: 90.15%\n",
      "\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.1259, Train Accuracy: 96.41%\n",
      "Epoch 7, Validation Loss: 0.4260, Validation Accuracy: 90.68%\n",
      "\n",
      "Early stopping triggered. Stopping training...\n",
      "Fold 3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.1634, Train Accuracy: 78.08%\n",
      "Epoch 1, Validation Loss: 0.4680, Validation Accuracy: 87.08%\n",
      "\n",
      "Fold 3: Save 0 epoch result. Loss = 0.4680\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.3524, Train Accuracy: 90.23%\n",
      "Epoch 2, Validation Loss: 0.4382, Validation Accuracy: 88.12%\n",
      "\n",
      "Fold 3: Save 1 epoch result. Loss = 0.4382\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2315, Train Accuracy: 93.13%\n",
      "Epoch 3, Validation Loss: 0.3880, Validation Accuracy: 89.75%\n",
      "\n",
      "Fold 3: Save 2 epoch result. Loss = 0.3880\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1849, Train Accuracy: 94.58%\n",
      "Epoch 4, Validation Loss: 0.4214, Validation Accuracy: 89.61%\n",
      "\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1538, Train Accuracy: 95.18%\n",
      "Epoch 5, Validation Loss: 0.4640, Validation Accuracy: 89.31%\n",
      "\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.1427, Train Accuracy: 95.80%\n",
      "Epoch 6, Validation Loss: 0.4164, Validation Accuracy: 89.95%\n",
      "\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.1362, Train Accuracy: 96.04%\n",
      "Epoch 7, Validation Loss: 0.4298, Validation Accuracy: 89.75%\n",
      "\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1133, Train Accuracy: 96.60%\n",
      "Epoch 8, Validation Loss: 0.4576, Validation Accuracy: 90.18%\n",
      "\n",
      "Early stopping triggered. Stopping training...\n",
      "Fold 4\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.1437, Train Accuracy: 78.06%\n",
      "Epoch 1, Validation Loss: 0.4876, Validation Accuracy: 86.58%\n",
      "\n",
      "Fold 4: Save 0 epoch result. Loss = 0.4876\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.3309, Train Accuracy: 90.68%\n",
      "Epoch 2, Validation Loss: 0.4659, Validation Accuracy: 88.25%\n",
      "\n",
      "Fold 4: Save 1 epoch result. Loss = 0.4659\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2336, Train Accuracy: 92.94%\n",
      "Epoch 3, Validation Loss: 0.4550, Validation Accuracy: 88.98%\n",
      "\n",
      "Fold 4: Save 2 epoch result. Loss = 0.4550\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1908, Train Accuracy: 94.15%\n",
      "Epoch 4, Validation Loss: 0.3965, Validation Accuracy: 90.31%\n",
      "\n",
      "Fold 4: Save 3 epoch result. Loss = 0.3965\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1480, Train Accuracy: 95.62%\n",
      "Epoch 5, Validation Loss: 0.4041, Validation Accuracy: 90.28%\n",
      "\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.1440, Train Accuracy: 95.86%\n",
      "Epoch 6, Validation Loss: 0.4112, Validation Accuracy: 90.65%\n",
      "\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.1334, Train Accuracy: 96.19%\n",
      "Epoch 7, Validation Loss: 0.4355, Validation Accuracy: 90.45%\n",
      "\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1223, Train Accuracy: 96.50%\n",
      "Epoch 8, Validation Loss: 0.4196, Validation Accuracy: 90.58%\n",
      "\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.1065, Train Accuracy: 96.83%\n",
      "Epoch 9, Validation Loss: 0.4531, Validation Accuracy: 90.38%\n",
      "\n",
      "Early stopping triggered. Stopping training...\n",
      "Fold 5\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.1852, Train Accuracy: 77.37%\n",
      "Epoch 1, Validation Loss: 0.4423, Validation Accuracy: 87.98%\n",
      "\n",
      "Fold 5: Save 0 epoch result. Loss = 0.4423\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.3238, Train Accuracy: 90.87%\n",
      "Epoch 2, Validation Loss: 0.4146, Validation Accuracy: 88.91%\n",
      "\n",
      "Fold 5: Save 1 epoch result. Loss = 0.4146\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2257, Train Accuracy: 93.33%\n",
      "Epoch 3, Validation Loss: 0.4458, Validation Accuracy: 88.52%\n",
      "\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.2185, Train Accuracy: 93.77%\n",
      "Epoch 4, Validation Loss: 0.4172, Validation Accuracy: 89.35%\n",
      "\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1708, Train Accuracy: 94.72%\n",
      "Epoch 5, Validation Loss: 0.4142, Validation Accuracy: 89.98%\n",
      "\n",
      "Fold 5: Save 4 epoch result. Loss = 0.4142\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.1517, Train Accuracy: 95.55%\n",
      "Epoch 6, Validation Loss: 0.4337, Validation Accuracy: 89.08%\n",
      "\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.1221, Train Accuracy: 96.41%\n",
      "Epoch 7, Validation Loss: 0.4061, Validation Accuracy: 90.38%\n",
      "\n",
      "Fold 5: Save 6 epoch result. Loss = 0.4061\n",
      "Early stopping triggered. Stopping training...\n"
     ]
    }
   ],
   "source": [
    "# Stratified K-Fold 설정\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "for fold_idx, (train_index, val_index) in enumerate(skf.split(train_info, train_info['target']), 1):\n",
    "    print(f'Fold {fold_idx}')\n",
    "\n",
    "    # 각 폴드에 따라 데이터 분리\n",
    "    train_df = train_info.iloc[train_index].reset_index(drop=True)\n",
    "    val_df = train_info.iloc[val_index].reset_index(drop=True)\n",
    "\n",
    "    # Transform 설정\n",
    "    transform_selector = TransformSelector(\n",
    "        transform_type=\"torchvision\"\n",
    "    )\n",
    "    train_transform = transform_selector.get_transform(is_train=True)\n",
    "    val_transform = transform_selector.get_transform(is_train=False)\n",
    "\n",
    "    # Dataset 생성\n",
    "    train_dataset = CustomDataset(\n",
    "        root_dir=traindata_dir,\n",
    "        info_df=train_df,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    val_dataset = CustomDataset(\n",
    "        root_dir=traindata_dir,\n",
    "        info_df=val_df,\n",
    "        transform=val_transform\n",
    "    )\n",
    "\n",
    "    # DataLoader에서 worker_init_fn을 설정하여 각 워커의 시드를 고정\n",
    "    def worker_init_fn(worker_id):\n",
    "        np.random.seed(seed + worker_id)\n",
    "        random.seed(seed + worker_id)\n",
    "\n",
    "    # DataLoader 생성\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=64, \n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=worker_init_fn\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=64, \n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=worker_init_fn\n",
    "    )\n",
    "\n",
    "    # 학습에 사용할 Model을 선언.\n",
    "    model_selector = ModelSelector(\n",
    "        model_type='timm', \n",
    "        num_classes=num_classes,\n",
    "        model_name='eva02_large_patch14_448.mim_m38m_ft_in22k_in1k', \n",
    "        pretrained=True\n",
    "    )\n",
    "    model = model_selector.get_model()\n",
    "\n",
    "    # 선언된 모델을 학습에 사용할 장비로 셋팅.\n",
    "    model.to(device)\n",
    "\n",
    "    # 모델의 모든 파라미터를 동결 (학습되지 않도록 설정)\n",
    "    for name, param in model.named_parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # block.22, block.23과 head 레이어만 학습되도록 설정\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'blocks.23' in name or 'head' in name:\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # optimizer 설정\n",
    "    optimizer = optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), \n",
    "        lr=0.001\n",
    "    )\n",
    "\n",
    "    # 스케줄러 초기화\n",
    "    # scheduler_step_size = 30  # 매 30step마다 학습률 감소\n",
    "    scheduler_gamma = 0.1  # 학습률을 현재의 10%로 감소\n",
    "\n",
    "    # 한 epoch당 step 수 계산\n",
    "    steps_per_epoch = len(train_loader)\n",
    "\n",
    "    # 2 epoch마다 학습률을 감소시키는 스케줄러 선언\n",
    "    epochs_per_lr_decay = 2\n",
    "    scheduler_step_size = steps_per_epoch * epochs_per_lr_decay\n",
    "\n",
    "    scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer, \n",
    "        step_size=scheduler_step_size, \n",
    "        gamma=scheduler_gamma\n",
    "    )\n",
    "\n",
    "    # 학습에 사용할 Loss를 선언.\n",
    "    loss_fn = Loss()\n",
    "\n",
    "    # 결과 저장 경로 수정\n",
    "    fold_result_path = os.path.join(save_result_path, f'fold_{fold_idx}')\n",
    "    os.makedirs(fold_result_path, exist_ok=True)\n",
    "\n",
    "    # 앞서 선언한 필요 class와 변수들을 조합해, 학습을 진행할 Trainer를 선언. \n",
    "    trainer = Trainer(\n",
    "        model=model, \n",
    "        device=device, \n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader, \n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        loss_fn=loss_fn, \n",
    "        epochs=50,\n",
    "        result_path=fold_result_path,\n",
    "        fold_idx=fold_idx  # 폴드 인덱스 전달\n",
    "    )\n",
    "\n",
    "    # 모델 학습.\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11087088-9b1f-4f7d-8eb5-72008cc88a50",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bf92c3c-7b38-4f89-af2a-5dfbabf51926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 추론을 위한 함수\n",
    "def ensemble_inference(\n",
    "    models: List[nn.Module], \n",
    "    device: torch.device, \n",
    "    test_loader: DataLoader\n",
    "):\n",
    "    # 모든 모델을 평가 모드로 설정\n",
    "    for model in models:\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    with torch.no_grad():  # Gradient 계산을 비활성화\n",
    "        for images in tqdm(test_loader):\n",
    "            # 데이터를 같은 장치로 이동\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # 각 모델로부터 예측 수행\n",
    "            outputs = []\n",
    "            for model in models:\n",
    "                logits = model(images)\n",
    "                probs = F.softmax(logits, dim=1)\n",
    "                outputs.append(probs)\n",
    "            \n",
    "            # 예측 결과를 앙상블 (평균)\n",
    "            avg_probs = torch.stack(outputs).mean(dim=0)\n",
    "            preds = avg_probs.argmax(dim=1)\n",
    "            \n",
    "            # 예측 결과 저장\n",
    "            predictions.extend(preds.cpu().detach().numpy())  # 결과를 CPU로 옮기고 리스트에 추가\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b407c24c-785d-4ffc-b17b-84ae7dc4ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 데이터의 경로와 정보를 가진 파일의 경로를 설정.\n",
    "testdata_dir = \"/data/ephemeral/home/data/test\"\n",
    "testdata_info_file = \"/data/ephemeral/home/data/test.csv\"\n",
    "save_result_path = \"/data/ephemeral/home/youngtae/model2/ensemble_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbb89c12-3b5d-4647-a8c2-83650dce6281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 데이터의 class, image path, target에 대한 정보가 들어있는 csv파일을 읽기.\n",
    "test_info = pd.read_csv(testdata_info_file)\n",
    "\n",
    "# 총 class 수.\n",
    "num_classes = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecec8773-6045-401e-b307-0a9758374c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론에 사용할 Transform을 선언.\n",
    "transform_selector = TransformSelector(\n",
    "    transform_type = \"torchvision\"\n",
    ")\n",
    "test_transform = transform_selector.get_transform(is_train=False)\n",
    "\n",
    "# 추론에 사용할 Dataset을 선언.\n",
    "test_dataset = CustomDataset(\n",
    "    root_dir=testdata_dir,\n",
    "    info_df=test_info,\n",
    "    transform=test_transform,\n",
    "    is_inference=True\n",
    ")\n",
    "\n",
    "# DataLoader에서 worker_init_fn을 설정하여 각 워커의 시드를 고정\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(seed + worker_id)\n",
    "    random.seed(seed + worker_id)\n",
    "\n",
    "# 추론에 사용할 DataLoader를 선언.\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    worker_init_fn=worker_init_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99cc06c1-ce65-476b-8d5b-b8025fcde443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론에 사용할 장비를 선택.\n",
    "# torch라이브러리에서 gpu를 인식할 경우, cuda로 설정.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 앙상블할 모델들을 저장할 리스트\n",
    "models = []\n",
    "\n",
    "# 각 폴드의 모델을 불러오기\n",
    "for fold_idx in range(1, n_splits + 1):\n",
    "    # 모델 초기화\n",
    "    model_selector = ModelSelector(\n",
    "        model_type='timm', \n",
    "        num_classes=num_classes,\n",
    "        model_name='eva02_large_patch14_448.mim_m38m_ft_in22k_in1k', \n",
    "        pretrained=False\n",
    "    )\n",
    "    model = model_selector.get_model()\n",
    "\n",
    "    # 모델의 모든 파라미터를 동결 (학습되지 않도록 설정)\n",
    "    for name, param in model.named_parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # block.22, block.23과 head 레이어만 학습되도록 설정\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'blocks.23' in name or 'head' in name:\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # 모델 가중치 로드\n",
    "    fold_result_path = os.path.join(save_result_path, f'fold_{fold_idx}')\n",
    "    model_path = os.path.join(fold_result_path, f'fold_{fold_idx}_best_model.pt')\n",
    "    model.load_state_dict(\n",
    "        torch.load(\n",
    "            model_path,\n",
    "            map_location=device\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 모델을 리스트에 추가\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "514852af-f338-4b27-a5a5-8b65406a8023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [52:26<00:00, 20.04s/it]\n"
     ]
    }
   ],
   "source": [
    "# predictions를 CSV에 저장할 때 형식을 맞춰서 저장\n",
    "# 앙상블 추론 함수 호출\n",
    "predictions = ensemble_inference(\n",
    "    models=models, \n",
    "    device=device, \n",
    "    test_loader=test_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc96c889-2423-42b2-8c3c-4b1d364ece71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>image_path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.JPEG</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.JPEG</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.JPEG</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.JPEG</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.JPEG</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>10009</td>\n",
       "      <td>10009.JPEG</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>10010</td>\n",
       "      <td>10010.JPEG</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>10011</td>\n",
       "      <td>10011.JPEG</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>10012</td>\n",
       "      <td>10012.JPEG</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>10013</td>\n",
       "      <td>10013.JPEG</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10014 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  image_path  target\n",
       "0          0      0.JPEG     328\n",
       "1          1      1.JPEG     414\n",
       "2          2      2.JPEG     493\n",
       "3          3      3.JPEG      17\n",
       "4          4      4.JPEG     388\n",
       "...      ...         ...     ...\n",
       "10009  10009  10009.JPEG     235\n",
       "10010  10010  10010.JPEG     191\n",
       "10011  10011  10011.JPEG     466\n",
       "10012  10012  10012.JPEG     258\n",
       "10013  10013  10013.JPEG     210\n",
       "\n",
       "[10014 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 클래스에 대한 예측 결과를 하나의 문자열로 합침\n",
    "test_info['target'] = predictions\n",
    "test_info = test_info.reset_index().rename(columns={\"index\": \"ID\"})\n",
    "test_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4efd2f6-d74a-491b-a7b1-fd7cf96f45a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# DataFrame 저장\n",
    "test_info.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac79e3df-e5c3-4a49-b37e-0dea1300c317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
